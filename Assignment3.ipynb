{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3xQa6VlNAOe"
   },
   "source": [
    "# Assignment 3\n",
    "## s3843790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "0mG3n0qRNTSA",
    "outputId": "cb0eadbd-b8a8-41b1-e3b4-7f44b47a8804"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load MovieLens 100K dataset into a dataframe of pandas\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hFJT0QWudp1P"
   },
   "outputs": [],
   "source": [
    "# Select 500 most active users and 500 most active items from the dataset\n",
    "n_most_active_users = 500\n",
    "n_most_active_items = 500\n",
    "\n",
    "user_ids = df.groupby('user_id').count().sort_values(by='rating', ascending=False).head(n_most_active_users).index\n",
    "item_ids = df.groupby('item_id').count().sort_values(by='rating', ascending=False).head(n_most_active_items).index\n",
    "df = df[(df['user_id'].isin(user_ids)) & (df['item_id'].isin(item_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r012fu0jJkJc"
   },
   "outputs": [],
   "source": [
    "# Map new internal ID for items\n",
    "i_ids = df['item_id'].unique().tolist()\n",
    "item_dict = dict(zip(i_ids, [i for i in range(len(i_ids))]))\n",
    "df['item_id'] = df['item_id'].map(item_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ3rlC7jO6WJ"
   },
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwS00lvHO-ca",
    "outputId": "f9f3a031-b4e7-439e-c3e3-c165b2286d19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-fb140fbf3b12>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
      "<ipython-input-4-fb140fbf3b12>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n"
     ]
    }
   ],
   "source": [
    "# The number of training users and active users\n",
    "n_training_users = 300\n",
    "n_active_users = n_most_active_users - n_training_users\n",
    "\n",
    "# The number of GIVEN ratings for active users\n",
    "GIVEN = 20\n",
    "\n",
    "# Randomly select users from the most active users as training set\n",
    "random_uids = np.random.choice(df.user_id.unique(), n_training_users, replace=False)\n",
    "train_df = df[df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all users in the training set\n",
    "u_ids = train_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
    "\n",
    "# The rest of users are active users for testing\n",
    "remain_df = df[~df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all active users\n",
    "u_ids = remain_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n",
    "\n",
    "# Randomly select GIVEN ratings for active users\n",
    "active_df = remain_df.groupby('user_id').sample(n=GIVEN, random_state=1024)\n",
    "\n",
    "test_df = remain_df[~remain_df.index.isin(active_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-ke62G3jiYb",
    "outputId": "1c135984-edb4-4f2b-fc73-9225d86a0c38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        3.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  2.0  0.0  4.0  0.0  4.0  4.0  0.0  0.0  2.0  ...  0.0  4.0  4.0   \n",
       " 2        0.0  0.0  4.0  4.0  4.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 3        4.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 4        0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 295      0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  4.0  5.0  ...  0.0  0.0  4.0   \n",
       " 296      0.0  0.0  5.0  4.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       " 297      0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 298      0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  3.0  4.0  0.0   \n",
       " 299      0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  3.0  0.0  ...  4.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  4.0  0.0  3.0  0.0  \n",
       " 1        0.0  3.0  3.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 295      0.0  4.0  2.0  3.0  0.0  0.0  0.0  \n",
       " 296      0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       " 297      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 298      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 299      5.0  0.0  0.0  3.0  0.0  0.0  0.0  \n",
       " \n",
       " [300 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  0.0  4.0  0.0  0.0  2.0  3.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 197      4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  5.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 196      0.0  0.0  0.0  0.0  5.0  0.0  0.0  \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        4.0  0.0  5.0  0.0  1.0  0.0  3.0  2.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  4.0  0.0  4.0  3.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       " 2        0.0  0.0  0.0  0.0  0.0  5.0  4.0  4.0  0.0  5.0  ...  3.0  0.0  0.0   \n",
       " 3        4.0  0.0  5.0  0.0  0.0  0.0  4.0  2.0  0.0  2.0  ...  0.0  3.0  0.0   \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  4.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  4.0  0.0  5.0  0.0  0.0  0.0  4.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  0.0  4.0  ...  4.0  0.0  0.0   \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  4.0   \n",
       " 198      4.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 199      0.0  0.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  5.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        4.0  1.0  0.0  0.0  0.0  0.0  2.0  \n",
       " 1        0.0  0.0  2.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  3.0  \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 199      0.0  0.0  3.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the format of datasets to matrices\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_training_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_training_users), 'rating': 0})\n",
    "train_ds = df_zeros.merge(train_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_active_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_active_users), 'rating': 0})\n",
    "active_ds = df_zeros.merge(active_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "test_ds = df_zeros.merge(test_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "train_ds, active_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yElYv2TDKKGu"
   },
   "outputs": [],
   "source": [
    "# Predicting All Missing Data in training set\n",
    "imputed_train_ds = train_ds.values.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy4FurbHD4dt"
   },
   "source": [
    "# Your implementation to predict the missing values\n",
    "(Put all your implementation for your algorithm in the following cell only to handle the missing values; )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zYh1bVd0ncz3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-19c64ec11f3a>:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return((min(sum(inters),GAMMA)/GAMMA)*np.sum(ra*ru)/(np.sqrt(np.sum(ra*ra))*np.sqrt(np.sum(ru*ru))))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-7-19c64ec11f3a>:43: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return((min(sum(inters),DELTA)/DELTA)*np.sum(ri*rj)/(np.sqrt(np.sum(ri*ri))*np.sqrt(np.sum(rj*rj))))\n"
     ]
    }
   ],
   "source": [
    "## Put all your implementation for your solution in this cell only to predict the missing values; \n",
    "## NOTE 1: DO NOT change anything in the rest of the cells in this framework, \n",
    "## otherwise the changes might cause errors and make your implementation invalid.\n",
    "\n",
    "## Note 2: \n",
    "## The user-item rating matrix is imputed_train_ds, \n",
    "## and the missing values are those 0s in imputed_train_ds. \n",
    "## You are required to predict them by using the solution in the given report. \n",
    "\n",
    "## The following parameters are required in the given report, \n",
    "## which is named \"Effective Missing Data Prediction for Collaborative Filtering\", \n",
    "## and you will need to use them. But, please do not change their values. \n",
    "LAMBDA = 0.7    # λ\n",
    "GAMMA = 10      # γ\n",
    "DELTA = 10      # δ\n",
    "ITA = 0.7       # η\n",
    "THETA = 0.7     # θ\n",
    "EPSILON = 1e-9\n",
    "imputed_train_ds_copy=imputed_train_ds.copy()\n",
    "\n",
    "def Sim_U(a,u,GAMMA):\n",
    "    U_a=imputed_train_ds[a,:] #extract the data vector of a 'th' user\n",
    "    U_u=imputed_train_ds[u,:] #extract the data vector of u 'th' user\n",
    "    inters=U_a*U_u!=0 # intersection of above two sets\n",
    "    U_a=U_a[inters] # select common items\n",
    "    mean_ra=np.mean(U_a)\n",
    "    ra=U_a-mean_ra\n",
    "    U_u=U_u[inters]# select common items\n",
    "    mean_ru=np.mean(U_u)\n",
    "    ru=U_u-mean_ru\n",
    "    return((min(sum(inters),GAMMA)/GAMMA)*np.sum(ra*ru)/(np.sqrt(np.sum(ra*ra))*np.sqrt(np.sum(ru*ru))))\n",
    "\n",
    "def Sim_I(i,j,DELTA):\n",
    "    I_i=imputed_train_ds[:,i] #extract the data vector of i 'th' item\n",
    "    I_j=imputed_train_ds[:,j] #extract the data vector of j 'th' item\n",
    "    inters=I_i*I_j!=0 # intersection of above two set\n",
    "    I_i=I_i[inters] # select common users\n",
    "    mean_ri=np.mean(I_i)\n",
    "    ri=I_i-mean_ri\n",
    "    I_j=I_j[inters] # select common users\n",
    "    mean_rj=np.mean(I_j)\n",
    "    rj=I_j-mean_rj\n",
    "    return((min(sum(inters),DELTA)/DELTA)*np.sum(ri*rj)/(np.sqrt(np.sum(ri*ri))*np.sqrt(np.sum(rj*rj))))\n",
    "\n",
    "## Find similar users\n",
    "def Sim_users(u_indx,GAMMA,ITA):\n",
    "    indx_array=[]\n",
    "    for i in range(imputed_train_ds.shape[0]):\n",
    "        if i!=u_indx:\n",
    "            if Sim_U(i,u_indx,GAMMA)>ITA: #Check the condition\n",
    "                indx_array.append(i)\n",
    "    return(indx_array)\n",
    "\n",
    "## Find similar items\n",
    "def Sim_items(i_indx,DELTA,THETA):\n",
    "    indx_array=[]\n",
    "    for i in range(imputed_train_ds.shape[1]):\n",
    "        if i!=i_indx:\n",
    "            if Sim_I(i,i_indx,DELTA)>THETA: #Check the condition\n",
    "                indx_array.append(i)\n",
    "    return(indx_array)\n",
    "\n",
    "def P_u(u_indx,i_indx,GAMMA):\n",
    "    S_u=Sim_users_array[u_indx] # Find similar users\n",
    "    Sum_numerator=0\n",
    "    Sum_denominator=0\n",
    "    for u in S_u:\n",
    "        Sum_numerator+=Sim_U(u_indx,u,GAMMA)*(imputed_train_ds[u,i_indx]-np.mean(imputed_train_ds[u,:]))# Find the sum of numerator\n",
    "        Sum_denominator+=Sim_U(u_indx,u,GAMMA) # Find the sum of denominator\n",
    "    return(np.mean(imputed_train_ds[u_indx,:])+(Sum_numerator/Sum_denominator))\n",
    "\n",
    "def P_i(u_indx,i_indx,DELTA):\n",
    "    S_i=Sim_items_array[i_indx] # Find similar items\n",
    "    Sum_numerator=0\n",
    "    Sum_denominator=0\n",
    "    for i in S_i:\n",
    "        Sum_numerator+=Sim_I(i_indx,i,DELTA)*(imputed_train_ds[u_indx,i]-np.mean(imputed_train_ds[:,i])) # Find the sum of numerator\n",
    "        Sum_denominator+=Sim_I(i_indx,i,DELTA) # Find the sum of denominator\n",
    "    return(np.mean(imputed_train_ds[:,i_indx])+(Sum_numerator/Sum_denominator))\n",
    "\n",
    "## Main function to calculate missing values\n",
    "def P_ui(u_indx,i_indx,LAMBDA,DELTA,GAMMA):\n",
    "    Similar_users=Sim_users_array[u_indx]\n",
    "    Similar_items=Sim_items_array[i_indx]\n",
    "    if len(Similar_users)==0 and len(Similar_items)==0:\n",
    "        P=0\n",
    "    elif len(Similar_users)==0:\n",
    "        P=P_i(u_indx,i_indx,DELTA)\n",
    "    elif len(Similar_items)==0:\n",
    "        P=P_u(u_indx,i_indx,GAMMA)\n",
    "    else:\n",
    "        P=LAMBDA*P_u(u_indx,i_indx,GAMMA)+(1-LAMBDA)*P_i(u_indx,i_indx,DELTA)\n",
    "    return(P)\n",
    "\n",
    "## Find similar users for each individual user\n",
    "Sim_users_array=[]\n",
    "for u_indx in range(imputed_train_ds.shape[0]):\n",
    "        Sim_users_array.append(Sim_users(u_indx,GAMMA,ITA)) #append similar users to an array\n",
    "\n",
    "## Find similar items for each individual item\n",
    "Sim_items_array=[]\n",
    "for i_indx in range(imputed_train_ds.shape[1]):\n",
    "        Sim_items_array.append(Sim_items(i_indx,DELTA,THETA)) #append similar items to an array\n",
    "\n",
    "for u_indx in range(imputed_train_ds.shape[0]):\n",
    "    for i_indx in range(imputed_train_ds.shape[1]):\n",
    "        if imputed_train_ds[u_indx,i_indx]==0:\n",
    "            imputed_train_ds_copy[u_indx,i_indx]=P_ui(u_indx,i_indx,LAMBDA,DELTA,GAMMA) #update missing values\n",
    "    # print(str(u_indx+1)+\"/\"+str(imputed_train_ds.shape[0])+\" completed\")  # used to check that program works & didn't\n",
    "    # freeze since this process takes a very long time. Not necessary for the code to run properly.\n",
    "imputed_train_ds=imputed_train_ds_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbOfVWTV_Aij"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Txs8YjwTzuSP"
   },
   "source": [
    "### Compute Pearson Correlation Coefficient of All Pairs of Items between active set and imputed training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "KoOgX_axKKGw",
    "outputId": "37a7adbd-e0d6-4375-e28c-3940977896f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.237974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.153772</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.598356</td>\n",
       "      <td>0.566452</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.308775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.169716</td>\n",
       "      <td>0.322944</td>\n",
       "      <td>-0.066644</td>\n",
       "      <td>0.646821</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.216322</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.545268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.419573</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.672067</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.633000</td>\n",
       "      <td>1.132040</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954546</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.849397</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.123036</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>1.487580</td>\n",
       "      <td>0.663396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.825242</td>\n",
       "      <td>0.888495</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.598356</td>\n",
       "      <td>0.566452</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.057760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.169716</td>\n",
       "      <td>0.190260</td>\n",
       "      <td>-0.066644</td>\n",
       "      <td>-0.189352</td>\n",
       "      <td>-0.536470</td>\n",
       "      <td>0.316718</td>\n",
       "      <td>-0.311899</td>\n",
       "      <td>-0.245128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.465549</td>\n",
       "      <td>1.460722</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.424592</td>\n",
       "      <td>0.478430</td>\n",
       "      <td>0.988070</td>\n",
       "      <td>1.627385</td>\n",
       "      <td>-0.407331</td>\n",
       "      <td>2.393344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013292</td>\n",
       "      <td>1.325966</td>\n",
       "      <td>-0.475574</td>\n",
       "      <td>0.345352</td>\n",
       "      <td>-0.444652</td>\n",
       "      <td>-0.481465</td>\n",
       "      <td>-0.192456</td>\n",
       "      <td>0.999246</td>\n",
       "      <td>-0.518229</td>\n",
       "      <td>-0.425758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.289773</td>\n",
       "      <td>0.274970</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.588332</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.421707</td>\n",
       "      <td>0.412136</td>\n",
       "      <td>1.803200</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295163</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.644324</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.222207</td>\n",
       "      <td>0.185395</td>\n",
       "      <td>0.376117</td>\n",
       "      <td>0.086113</td>\n",
       "      <td>0.148630</td>\n",
       "      <td>0.263837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.825242</td>\n",
       "      <td>0.835183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.153772</td>\n",
       "      <td>1.006912</td>\n",
       "      <td>0.598356</td>\n",
       "      <td>0.566452</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.047261</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.325478</td>\n",
       "      <td>-0.311899</td>\n",
       "      <td>-0.818880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2.925773</td>\n",
       "      <td>-0.162690</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.121733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.848136</td>\n",
       "      <td>2.339200</td>\n",
       "      <td>-0.033291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135518</td>\n",
       "      <td>-0.174000</td>\n",
       "      <td>2.001259</td>\n",
       "      <td>2.664022</td>\n",
       "      <td>0.053620</td>\n",
       "      <td>-0.058569</td>\n",
       "      <td>0.012117</td>\n",
       "      <td>2.522113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.212595</td>\n",
       "      <td>0.094429</td>\n",
       "      <td>-0.049968</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.247097</td>\n",
       "      <td>0.144529</td>\n",
       "      <td>0.350816</td>\n",
       "      <td>2.186520</td>\n",
       "      <td>-0.017649</td>\n",
       "      <td>2.607886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318621</td>\n",
       "      <td>-0.049968</td>\n",
       "      <td>1.030406</td>\n",
       "      <td>-0.048564</td>\n",
       "      <td>-0.054971</td>\n",
       "      <td>1.024516</td>\n",
       "      <td>1.292480</td>\n",
       "      <td>-0.191064</td>\n",
       "      <td>-0.128547</td>\n",
       "      <td>-0.253310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2.553373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.551932</td>\n",
       "      <td>0.205867</td>\n",
       "      <td>0.385307</td>\n",
       "      <td>0.418519</td>\n",
       "      <td>2.666800</td>\n",
       "      <td>0.223128</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.154885</td>\n",
       "      <td>0.191622</td>\n",
       "      <td>0.482171</td>\n",
       "      <td>0.148995</td>\n",
       "      <td>0.044859</td>\n",
       "      <td>0.485003</td>\n",
       "      <td>0.112230</td>\n",
       "      <td>0.419404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.082148</td>\n",
       "      <td>0.457765</td>\n",
       "      <td>4.763679</td>\n",
       "      <td>1.702117</td>\n",
       "      <td>-0.014354</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>1.417607</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.502434</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.236321</td>\n",
       "      <td>-0.216340</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.008687</td>\n",
       "      <td>-0.034091</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.895617</td>\n",
       "      <td>0.177281</td>\n",
       "      <td>-0.386986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    3.000000  1.237974  0.000000  1.153772  0.000223  0.598356  0.566452   \n",
       "1    4.419573  2.000000  0.960000  4.000000  0.672067  4.000000  4.000000   \n",
       "2    0.825242  0.888495  4.000000  4.000000  4.000000  0.598356  0.566452   \n",
       "3    4.000000 -0.465549  1.460722  2.000000 -0.424592  0.478430  0.988070   \n",
       "4    3.289773  0.274970  0.346000  0.588332  5.000000  0.421707  0.412136   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "295  0.825242  0.835183  0.000000  1.153772  1.006912  0.598356  0.566452   \n",
       "296  2.925773 -0.162690  5.000000  4.000000 -0.121733  1.000000  2.848136   \n",
       "297  0.212595  0.094429 -0.049968  5.000000  0.247097  0.144529  0.350816   \n",
       "298  2.553373  1.000000  0.294000  0.551932  0.205867  0.385307  0.418519   \n",
       "299  0.082148  0.457765  4.763679  1.702117 -0.014354  0.014082  1.417607   \n",
       "\n",
       "          7         8         9    ...       490       491       492  \\\n",
       "0    4.000000  0.308775  0.000000  ...  0.505641  0.000000 -0.169716   \n",
       "1    1.633000  1.132040  2.000000  ...  0.954546  4.000000  4.000000   \n",
       "2    4.000000  0.057760  0.000000  ... -0.061670  0.000000 -0.169716   \n",
       "3    1.627385 -0.407331  2.393344  ... -0.013292  1.325966 -0.475574   \n",
       "4    1.803200  0.259528  4.000000  ...  0.295163  0.346000  0.644324   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "295  5.000000  4.000000  5.000000  ... -0.061670  0.000000  4.000000   \n",
       "296  2.339200 -0.033291  1.000000  ...  0.135518 -0.174000  2.001259   \n",
       "297  2.186520 -0.017649  2.607886  ...  0.318621 -0.049968  1.030406   \n",
       "298  2.666800  0.223128  0.294000  ...  3.000000  4.000000  0.154885   \n",
       "299  3.000000  3.000000  1.502434  ...  4.000000 -0.236321 -0.216340   \n",
       "\n",
       "          493       494       495       496       497       498       499  \n",
       "0    0.322944 -0.066644  0.646821  4.000000  0.216322  3.000000 -0.545268  \n",
       "1    0.849397  3.000000  3.000000  1.123036  0.749687  1.487580  0.663396  \n",
       "2    0.190260 -0.066644 -0.189352 -0.536470  0.316718 -0.311899 -0.245128  \n",
       "3    0.345352 -0.444652 -0.481465 -0.192456  0.999246 -0.518229 -0.425758  \n",
       "4    0.156765  0.222207  0.185395  0.376117  0.086113  0.148630  0.263837  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "295 -0.047261  4.000000  2.000000  3.000000 -0.325478 -0.311899 -0.818880  \n",
       "296  2.664022  0.053620 -0.058569  0.012117  2.522113  1.000000  0.120689  \n",
       "297 -0.048564 -0.054971  1.024516  1.292480 -0.191064 -0.128547 -0.253310  \n",
       "298  0.191622  0.482171  0.148995  0.044859  0.485003  0.112230  0.419404  \n",
       "299  5.000000 -0.008687 -0.034091  3.000000  0.895617  0.177281 -0.386986  \n",
       "\n",
       "[300 rows x 500 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_train_ds = pd.DataFrame(imputed_train_ds)\n",
    "imputed_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq0uq1aHzu11",
    "outputId": "f6214a46-d63e-4fdc-e7dd-ccaed23b237d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.22379811,  0.21983795,  0.27650809, ...,  0.24981217,\n",
       "         0.02232371,  0.37308651],\n",
       "       [ 0.19751566,  0.14858505,  0.46853096, ...,  0.3894791 ,\n",
       "         0.00670074,  0.45691701],\n",
       "       [ 0.14712937, -0.29647016,  0.13144372, ..., -0.02500026,\n",
       "         0.1925939 , -0.18848681],\n",
       "       ...,\n",
       "       [ 0.11998261,  0.11996471, -0.30598424, ..., -0.12874992,\n",
       "        -0.10891419, -0.53042598],\n",
       "       [ 0.14410373,  0.28964422,  0.45282972, ...,  0.24310327,\n",
       "        -0.27447864, -0.09838197],\n",
       "       [-0.04252086, -0.24079386,  0.06788847, ...,  0.12457798,\n",
       "         0.34350265,  0.51207493]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_user_pearson_corr = np.zeros((active_ds.shape[0], train_ds.shape[0]))\n",
    "\n",
    "# Compute Pearson Correlation Coefficient of All Pairs of Users between active set and imputed training set\n",
    "for i, user_i_vec in enumerate(active_ds.values):\n",
    "    for j, user_j_vec in enumerate(imputed_train_ds.values):\n",
    "        \n",
    "        # ratings corated by the current pair od users\n",
    "        mask_i = user_i_vec > 0\n",
    "        mask_j = user_j_vec > 0\n",
    "\n",
    "        # corrated item index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of user_i_vec and user_j_vec\n",
    "        mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "        user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "        r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "        r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "        r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "        r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "        sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), GAMMA) / GAMMA) * sim\n",
    "\n",
    "        active_user_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "active_user_pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewTnN9kNb8Ys"
   },
   "source": [
    "## Predict Ratings of Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4ERndYXb8Ys",
    "outputId": "12607670-af61-403a-e4ce-f5e874bf8386"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.23349299, 0.        , 5.        , ..., 0.        , 0.        ,\n",
       "        2.1700854 ],\n",
       "       [0.        , 1.51679021, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [3.90022001, 0.        , 4.68826603, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 10\n",
    "\n",
    "test_ds_pred = np.zeros_like(test_ds.values)\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(test_ds.values):\n",
    "\n",
    "    if rating > 0:\n",
    "\n",
    "        sim_user_ids = np.argsort(active_user_pearson_corr[i])[-1:-(K + 1):-1]\n",
    "\n",
    "        #==================user-based==================#\n",
    "        # the coefficient values of similar users\n",
    "        sim_val = active_user_pearson_corr[i][sim_user_ids]\n",
    "\n",
    "        # the average value of the current user's ratings\n",
    "        sim_users = imputed_train_ds.values[sim_user_ids]\n",
    "        user_mean = np.sum(active_ds.values[i]) / (np.sum(np.clip(active_ds.values[i], 0, 1)) + EPSILON)\n",
    "        sim_user_mean = np.sum(sim_users, axis=1) / (np.sum(np.clip(sim_users, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # select the users who rated item j\n",
    "        mask_rated_j = sim_users[:, j] > 0\n",
    "        \n",
    "        # sim(u, v) * (r_vj - mean_v)\n",
    "        sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "        \n",
    "        user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "        user_based_pred = np.clip(user_based_pred, 0, 5)\n",
    "\n",
    "        test_ds_pred[i][j] = user_based_pred\n",
    "        \n",
    "test_ds_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUTn4kSFb8ZA"
   },
   "source": [
    "## Compute MAE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JCVmexyb8ZA",
    "outputId": "6f650170-e9a6-482a-b695-5fa474d964b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.9074049394793331, RMSE: 1.1564766884104771\n"
     ]
    }
   ],
   "source": [
    "# MAE\n",
    "MAE = np.sum(np.abs(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1))\n",
    "\n",
    "# RMSE\n",
    "RMSE = np.sqrt(np.sum(np.square(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1)))\n",
    "\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 1
}